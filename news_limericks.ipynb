{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limericks from the News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "from newsapi import NewsApiClient\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#News API Top Headlines\n",
    "my_key = '681331e3618f422795336e18bb57a528'\n",
    "\n",
    "def api_call(my_key):\n",
    "    newsapi = NewsApiClient(api_key=my_key)\n",
    "    top_headlines = newsapi.get_top_headlines(sources='the-new-york-times')\n",
    "    df = pd.DataFrame(top_headlines['articles'])\n",
    "    return df\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_segment(df):\n",
    "    df['text'] = df.title + df.description + df.content   \n",
    "    df2 = df.text.loc[0:4]\n",
    "    return pd.DataFrame(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nude Photos of Underage Girls Seized From Epst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkey’s Long, Painful Economic Crisis Grinds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iran Says It Has Surpassed Critical Nuclear En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Monroe Enslaved Hundreds. Their Descenda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Nude Photos of Underage Girls Seized From Epst...\n",
       "1  Turkey’s Long, Painful Economic Crisis Grinds ...\n",
       "2  Iran Says It Has Surpassed Critical Nuclear En...\n",
       "3  James Monroe Enslaved Hundreds. Their Descenda...\n",
       "4                                                NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = api_call('681331e3618f422795336e18bb57a528')\n",
    "df2 = data_segment(df)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format and parse articles\n",
    "\n",
    "def word_parse(x):\n",
    "    words = []\n",
    "    text = nlp(str(x))\n",
    "        \n",
    "    res = {\n",
    "            'nouns':[],\n",
    "            'verbs':[],\n",
    "            'adjectives':[],\n",
    "            'pronouns':[],\n",
    "            'adverbs':[],\n",
    "            'noun_chunks':[]\n",
    "        }\n",
    "            \n",
    "    for token in text:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            res['nouns'].append(token)\n",
    "        elif token.pos_ == 'VERB':\n",
    "            res['verbs'].append(token)\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            res['adjectives'].append(token)\n",
    "        elif token.pos_ == 'PRON':\n",
    "            res['pronouns'].append(token)\n",
    "        elif token.pos_ == 'ADV':\n",
    "            res['adverbs'].append(token)\n",
    "            \n",
    "    for chunk in text.noun_chunks:\n",
    "            res['noun_chunks'].append(chunk)\n",
    "        \n",
    "    words.append(res)\n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = []\n",
    "for index, row in df2.iterrows():\n",
    "    objs.append(word_parse(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'nouns': [proximity, crisis, households, businesses, spending, investment, face, growth, transactions, lira, economy, years, lira, companies, revenues, lira, debts, dollars, burdens, +1563, chars], 'verbs': [remains, stuck, defer, were, was, appreciating, was, expanding, has, fallen, have, seen, expand], 'adjectives': [Painful, perilous, economic, weak, Such, attractive, Turkish, recent], 'pronouns': [], 'adverbs': [then, rapidly], 'noun_chunks': [Painful Economic Crisis Grinds OnTurkey, perilous proximity, economic crisis, households, businesses, spending, investment, the face, weak growth, Such transactions, the lira, the Turkish economy, recent years, the lira, companies, revenues, lira, debts, dollars, their burdens, Turkeys… [+1563 chars]}]\n"
     ]
    }
   ],
   "source": [
    "print(objs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
